### EVA5 Session14 - 

#### RCNN Family

Dataset prepared as a Group
The below mention is our group for EVA 5 Phase 1. The mention below emails are LMS Login ID's.

- Aditya Jindal ([aditya.jindal4@gmail.com](mailto:aditya.jindal4@gmail.com))
- Shubham Agnihotri ([shubham.agnihotri1997@gmail.com](mailto:shubham.agnihotri1997@gmail.com))
- Shyamant Achar ([shyamant.achar@federateconsulting.com](mailto:shyamant.achar@federateconsulting.com))
- Sreekanth Zipsy ([sreekanthj244@gmail.com](mailto:sreekanthj244@gmail.com))

----

#### Assingment 14

- Look at the Midas model: [https://github.com/intel-isl/MiDaS](https://github.com/intel-isl/MiDaS)

- Look at PlaneRCNN model: https://github.com/NVlabs/planercnn

- Using your helmet, mask, PPE, and boots dataset.

- Run it through Midas and get depth images. 

- Run it through the PlaneRCNN model and get planer images only.

Now our PPE dataset contains [depth map_color map](https://drive.google.com/file/d/1AVCMM4-DauOWMggGFj4QUdsegh7vaSug/view?usp=sharing), [depth map grayscale](https://drive.google.com/file/d/1ZvF_52rYZwaIKuqvG4Xke5rml5lfXvPT/view?usp=sharing), [surface planes](https://drive.google.com/file/d/1KQZ9iQsI0J4jI2ynAiHpxFHKqLINw9As/view?usp=sharing), and [bounding boxes](https://drive.google.com/file/d/1wco-H1x3i1Ew8SFzfoqX5YGXMc4fMAkz/view?usp=sharing) for the classes.

*Notes on Midas:*

- Channel first RGB images are normalised using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225]
- Using pre-trained model which is inferred from 5 data-sets 
- Depth Estimation Colormap dataset is in VIRIDIS colormap in .JPG format
- Depth Estimation Gray dataset is in grayscale in .PNG format

*Notes on PlaneRCNN:*

- Plane in 3D space is determined by a point and a vector that is perpendicular to the plane.
- The Planes dataset created using PlaneR-CNN that detects arbitrary number of planes. Stored in .PNG format.
- The Region Proposal Network proposes bounding boxes that are likely to belong to an object. Positive and negative anchors along with anchor box refinement are visualised. 
- Final detection boxes and refinement is applied to the images, created masks are then scaled and placed on the image in the right location.
- Non-Maximum Suppression and  RoiAlign (i.e based on crop_and_resize) are build for the correct architecture.
- used **sm_60** arch for Tesla T4 Colab GPU
- tweaked "evaluate.py" and "visualize_utils.py" to save only surface planes. As the inference generated by the model is quite heavy in storage.
- used default camera intrinsic parameter for all the images in dataset.

---

#### Inference using MaskRCNN using Detectron2 Model 

- Helps us with features such as panoptic segmentation, densepose, cascade R-CNN, rotated bounding boxes, pointRend

[Panoptic Segmentation](https://youtu.be/PH4CNADtol4)